{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3b0cb12",
   "metadata": {},
   "source": [
    "# Библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163a4f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import scipy\n",
    "from scipy import stats\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import copy\n",
    "\n",
    "import tqdm\n",
    "import tqdm.notebook as tqdm\n",
    "\n",
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341bf402",
   "metadata": {},
   "source": [
    "# Стратификация"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4081c935",
   "metadata": {},
   "source": [
    "## Данные"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236a07b0",
   "metadata": {},
   "source": [
    "### Задаем ошибки 1 и 2 рода, ожидаемый эффект. Вычисляем необходимое число наблюдений в каждой группе"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f3e14a",
   "metadata": {},
   "source": [
    "![](img/effect_size.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea0a027",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_size(alpha, beta, std_a, std_b, effect):\n",
    "    '''\n",
    "    Вычисляет количество наблюдений в каждой группе при заданных:\n",
    "    alpha, beta - ошибках 1 и 2 рода, \n",
    "    std_a, std_b - стандартных отколениях в контрольной и экспериментальной группах,\n",
    "    effect - минимальном ожидаемом эффекте\n",
    "    '''\n",
    "    norm_rv = stats.norm(loc=0, scale=1)\n",
    "    t_alpha = norm_rv.ppf(1 - alpha / 2)\n",
    "    t_beta = norm_rv.ppf(1 - beta)\n",
    "    var = (std_a**2) + (std_b)**2\n",
    "    sample_size = int((t_alpha + t_beta) ** 2 * var / (effect ** 2))\n",
    "    return sample_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8ac259",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "beta = 0.2\n",
    "std_a = 800\n",
    "std_b = 800\n",
    "effect = 100\n",
    "\n",
    "sample_size = get_sample_size(alpha, beta, std_a, std_b, effect)\n",
    "sample_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afea7463",
   "metadata": {},
   "source": [
    "### Проверяем расчеты: ошибку первого рода на АА и ошибку второго рода на АВ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e246b49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_control = 2500\n",
    "mu_pilot = mu_control + effect\n",
    "std = 800\n",
    "\n",
    "first_type_errors = []\n",
    "second_type_errors = []\n",
    "\n",
    "for i in tqdm.tqdm(range(10000)):\n",
    "    \n",
    "    control_one = stats.norm(mu_control, std).rvs(sample_size)\n",
    "    control_two = stats.norm(mu_control, std).rvs(sample_size)\n",
    "    pilot = stats.norm(mu_pilot, std).rvs(sample_size)\n",
    "    \n",
    "    _, pvalue_aa = stats.ttest_ind(control_one, control_two)\n",
    "    first_type_errors.append(pvalue_aa < alpha)\n",
    "    _, pvalue_ab = stats.ttest_ind(control_one, pilot)\n",
    "    second_type_errors.append(pvalue_ab >= alpha)\n",
    "\n",
    "prop_first_type_errors = np.mean(first_type_errors)\n",
    "prop_second_type_errors = np.mean(second_type_errors)\n",
    "print(f'prop_first_type_errors = {prop_first_type_errors:0.3f}')\n",
    "print(f'prop_second_type_errors = {prop_second_type_errors:0.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3617b714",
   "metadata": {},
   "source": [
    "### Фунцкии для случайного и стратифицированного семплирования, а также сам тест"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61dc58ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_data(strats, sample_size, strat_to_param, effect = 0):\n",
    "    \"\"\"\n",
    "    Генерирует данные случайным семплированием.\n",
    "    Возвращает датафрейм со значениями метрики и номерами страт пользователей\n",
    "    в контрольной и экспериментальной группах:\n",
    "    strats - cписок с распределением страт в популяции,\n",
    "    sample_size - размеры групп,\n",
    "    strat_to_param - словарь с параметрами страт,\n",
    "    effect - размер эффекта\n",
    "    \"\"\"\n",
    "    \n",
    "    control_strats, pilot_strats = np.random.choice(strats, (2, sample_size), False)\n",
    "    \n",
    "    control, pilot = [], []\n",
    "    for strat, (_, mu, std) in strat_to_param.items():\n",
    "        n_control = np.sum(control_strats == strat)\n",
    "        n_pilot = np.sum(pilot_strats == strat)\n",
    "        control += [(x, strat) for x in stats.norm(mu, std).rvs(n_control)]\n",
    "        pilot += [(x, strat) for x in stats.norm(mu + effect, std).rvs(n_pilot)]\n",
    "        \n",
    "    control_df = pd.DataFrame(control, columns = ['value', 'strat'])\n",
    "    pilot_df = pd.DataFrame(pilot, columns = ['value', 'strat'])\n",
    "    return control_df, pilot_df\n",
    "\n",
    "def get_stratified_data(strat_to_param, effect = 0):\n",
    "    \"\"\"\n",
    "    Генерирует данные стратифицированным семплированием.\n",
    "    Возвращает датафрейм со значениями метрики и номерами страт пользователей\n",
    "    в контрольной и экспериментальной группах:\n",
    "    strat_to_param - словарь с параметрами страт\n",
    "    effect - размер эффекта\n",
    "    \"\"\"\n",
    "    control, pilot = [], []\n",
    "    for strat, (n, mu, std) in strat_to_param.items():\n",
    "        control += [(x, strat) for x in stats.norm(mu, std).rvs(n)]\n",
    "        pilot += [(x, strat) for x in stats.norm(mu + effect, std).rvs(n)]\n",
    "\n",
    "    control_df = pd.DataFrame(control, columns = ['value', 'strat'])\n",
    "    pilot_df = pd.DataFrame(pilot, columns = ['value', 'strat'])\n",
    "    return control_df, pilot_df\n",
    "\n",
    "def ttest(a: pd.DataFrame, b: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Возвращает p-value для теста Стьюдента (при равных дисперсиях):\n",
    "    a, b - датафреймы пользователей контрольной и экспериментальной групп\n",
    "    \"\"\"\n",
    "    _, pvalue = stats.ttest_ind(a['value'].values, b['value'].values)\n",
    "    return pvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087e52b1",
   "metadata": {},
   "source": [
    "## До коррекции:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b789811e",
   "metadata": {},
   "source": [
    "### Зная, что эффекта нет (effect = 0, АА тест), вычисляем ошибку первого рода при случайном и стратифицированном семплировании"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1473cd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10000                           # общее количество пользователей в популяции\n",
    "w_one, w_two = 0.5, 0.5             # доли страт в популяции\n",
    "N_one = int(N * w_one)              # количество пользователей первой страты\n",
    "N_two = int(N * w_two)              # количество пользователей второй страты\n",
    "mu_one, mu_two = 2000, 3000         # средние значения метрики в стратах\n",
    "std_one, std_two = 625, 625         # стандартное отклонение метрики в стратах\n",
    "\n",
    "# ! Будем считать, что при объединении страт в контрольной и экспериментальной группах стандартное отклоение составит 800\n",
    "# (именно для такого стандартного отклонения мы вначале рассчитывали количество наблюдений в группах)\n",
    "    \n",
    "strats = [1 for _ in range(N_one)] + [2 for _ in range(N_two)]\n",
    "\n",
    "sample_size = get_sample_size(alpha, beta, std_a, std_b, effect) + 100 # возьмем количество наблюдений в группах с запасом \n",
    "                                                                       # на 100 больше, чем нужно\n",
    "sample_size_one = int(sample_size * w_one)\n",
    "sample_size_two = int(sample_size * w_two)\n",
    "\n",
    "strat_to_param = {1: (sample_size_one, mu_one, std_one), 2: (sample_size_two, mu_two, std_two)}\n",
    "\n",
    "random_first_type_errors = []\n",
    "stratified_first_type_errors = []\n",
    "random_deltas = []\n",
    "stratified_deltas = []\n",
    "\n",
    "for _ in tqdm.tqdm(range(10000)):\n",
    "    # по умолчанию в функции генерации выборок эффекта нет\n",
    "    control_random, pilot_random = get_random_data(strats, sample_size, strat_to_param)\n",
    "    control_stratified, pilot_stratified = get_stratified_data(strat_to_param)\n",
    "    \n",
    "    random_deltas.append(pilot_random['value'].mean() - control_random['value'].mean())\n",
    "    stratified_deltas.append(pilot_stratified['value'].mean() - control_stratified['value'].mean())\n",
    "\n",
    "    pvalue_random = ttest(control_random, pilot_random)\n",
    "    random_first_type_errors.append(pvalue_random < alpha)\n",
    "    \n",
    "    pvalue_stratified = ttest(control_stratified, pilot_stratified)\n",
    "    stratified_first_type_errors.append(pvalue_stratified < alpha)\n",
    "\n",
    "prop_random_first_type_errors = np.mean(random_first_type_errors)\n",
    "prop_stratified_first_type_errors = np.mean(stratified_first_type_errors)\n",
    "print(f'prop_random_first_type_errors = {prop_random_first_type_errors:0.3f}')\n",
    "print(f'prop_stratified_first_type_errors = {prop_stratified_first_type_errors:0.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2805aa85",
   "metadata": {},
   "source": [
    "### Зная, что эффект есть (effect = 100, АВ тест), вычисляем ошибку второго рода при случайном и стратифицированном семплировании"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37aaf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "effect = 100\n",
    "random_second_type_errors = []\n",
    "stratified_second_type_errors = []\n",
    "\n",
    "for _ in tqdm.tqdm(range(10000)):\n",
    "    # добавляем эффект в функцию генерации\n",
    "    control_random, pilot_random = get_random_data(strats, sample_size, strat_to_param, effect)\n",
    "    control_stratified, pilot_stratified = get_stratified_data(strat_to_param, effect)\n",
    "    \n",
    "    pvalue_random = ttest(control_random, pilot_random)\n",
    "    random_second_type_errors.append(pvalue_random >= alpha)\n",
    "                                     \n",
    "    pvalue_stratified = ttest(control_stratified, pilot_stratified)\n",
    "    stratified_second_type_errors.append(pvalue_stratified >= alpha)\n",
    "\n",
    "prop_random_second_type_errors = np.mean(random_second_type_errors)\n",
    "prop_stratified_second_type_errors = np.mean(stratified_second_type_errors)\n",
    "print(f'prop_random_second_type_errors = {prop_random_second_type_errors:0.3f}')\n",
    "print(f'prop_stratified_second_type_errors = {prop_stratified_second_type_errors:0.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbaa415",
   "metadata": {},
   "source": [
    "Можно заметить, что при случайном семплировании ошибки первого и второго рода остались на прежнем уровне (впрочем, как и должно быть), а при стратифицированном семплировании ошибки первого и второго рода снизилась "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6a7340",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot({'Случайное семплирвоание': random_deltas, 'Стратифицированное семплирование': stratified_deltas}, kind='kde')\n",
    "plt.title('Распределение разницы средних при разных видах семплирования')\n",
    "plt.ylabel('Плотность')\n",
    "\n",
    "random_var_deltas = np.array(random_deltas).var(ddof = 1)\n",
    "stratified_var_deltas = np.array(stratified_deltas).var(ddof = 1)\n",
    "\n",
    "print(f'Дисперсия разницы средних при случаном семплировании: {random_var_deltas}')\n",
    "print(f'Дисперсия разницы средних при стратифицированном семплировании: {stratified_var_deltas}')\n",
    "\n",
    "print(f'Произошло снижение дисперсии разницы средних в {round(random_var_deltas / stratified_var_deltas, 2)} раз(а)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67b6b12",
   "metadata": {},
   "source": [
    "## После коррекции:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02f7d7b",
   "metadata": {},
   "source": [
    "Исправляем тест Стьюдента: вносим корректировку на стратифицированное семплирование (стратифицированный подсчет среднего)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c0d058",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_strat_mean(df: pd.DataFrame, weights: pd.Series):\n",
    "    \"\"\"\n",
    "    Считает стратифицированное среднее:\n",
    "    df - датафрейм с целевой метрикой и стратами, к которой относится пользователь\n",
    "    weights - серия {название страты: вес страты в популяции}\n",
    "    \"\"\"\n",
    "    strat_mean = df.groupby('strat')['value'].mean()\n",
    "    return (strat_mean * weights).sum()\n",
    "\n",
    "def calc_strat_var(df: pd.DataFrame, weights: pd.Series):\n",
    "    \"\"\"\n",
    "    Считает стратифицированную дисперсию:\n",
    "    df - датафрейм с целевой метрикой и стратами, к которой относится пользователь\n",
    "    weights - серия {название страты: вес страты в популяции}\n",
    "    \"\"\"\n",
    "    strat_var = df.groupby('strat')['value'].var(ddof = 1)\n",
    "    return (strat_var * weights).sum()\n",
    "\n",
    "def ttest_strat(a: pd.DataFrame, b: pd.DataFrame, weights: pd.Series, return_deltas = True):\n",
    "    \"\"\"\n",
    "    Возвращает pvalue теста Стьюдента (при равных дисперсиях) при подсчете стратифицированного среднего:\n",
    "    a, b - данные пользователей контрольной и экспериментальной групп\n",
    "    weights - серия {название страты: вес страты в популяции}\n",
    "    \"\"\"\n",
    "    a_strat_mean = calc_strat_mean(a, weights)\n",
    "    b_strat_mean = calc_strat_mean(b, weights)\n",
    "    a_strat_var = calc_strat_var(a, weights)\n",
    "    b_strat_var = calc_strat_var(b, weights)\n",
    "    delta = a_strat_mean - b_strat_mean\n",
    "    std = (a_strat_var / len(a) + b_strat_var / len(b)) ** 0.5\n",
    "    t = delta / std\n",
    "    \n",
    "    pvalue = 2 * (1 - stats.t(len(a) + len(b)).cdf(np.abs(t)))\n",
    "    \n",
    "#     Для случая неравных дисперсий:\n",
    "    \n",
    "#     v = ((a_strat_var / len(a) + b_strat_var / len(b)) ** 2) / \\\n",
    "#         ((a_strat_var ** 2 / (len(a) ** 2 * (len(a) - 1))) + \\\n",
    "#         (b_strat_var ** 2 / (len(b) ** 2 * (len(b) - 1)))) # приближение Уэлча\n",
    "#     pvalue = 2 * (1 - stats.t(v).cdf(np.abs(t)))\n",
    "\n",
    "    if return_deltas == True:\n",
    "        return (pvalue, delta)\n",
    "    else:\n",
    "        return pvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffba47fb",
   "metadata": {},
   "source": [
    "### Вычисляем ошибку первого (на АА тесте) и второго (на АВ тесте) рода при стратифицированном семплировании и стратифицированном среднем (и соответственно стратифицированной дисперсии)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e5b708",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = pd.Series({1: w_one, 2: w_two})\n",
    "\n",
    "first_type_errors = []\n",
    "second_type_errors = []\n",
    "\n",
    "stratified_deltas_strat_mean = []\n",
    "\n",
    "for _ in tqdm.tqdm(range(10000)):\n",
    "    control_aa, pilot_aa = get_stratified_data(strat_to_param)\n",
    "    control_ab, pilot_ab = get_stratified_data(strat_to_param, effect)\n",
    "\n",
    "    pvalue_aa, delta = ttest_strat(control_aa, pilot_aa, weights, return_deltas = True)\n",
    "    first_type_errors.append(pvalue_aa < alpha)\n",
    "    stratified_deltas_strat_mean.append(delta)\n",
    "    \n",
    "    pvalue_ab = ttest_strat(control_ab, pilot_ab, weights, return_deltas = False)\n",
    "    second_type_errors.append(pvalue_ab >= alpha)\n",
    "    \n",
    "prop_first_type_errors = np.mean(first_type_errors)\n",
    "prop_second_type_errors = np.mean(second_type_errors)\n",
    "print(f'prop_first_type_errors = {prop_first_type_errors:0.3f}')\n",
    "print(f'prop_second_type_errors = {prop_second_type_errors:0.3f}')\n",
    "print(f'Произошло снижение ошибки II рода в {round(prop_random_second_type_errors / prop_second_type_errors, 2)} раз(а)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ff28d9",
   "metadata": {},
   "source": [
    "Ошибка первого рода осталась на запланированном уровне, а ошибка второго рода снизилась (0.2 -> 0.035), а значит мощность теста повысилась"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51555f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot({'Случайное семплирвоание': random_deltas, 'Стратифицированное семплирование \\n (и стратифицированное среднее)': stratified_deltas_strat_mean}, kind='kde')\n",
    "plt.title('Распределение разницы средних при разных видах семплирования')\n",
    "plt.ylabel('Плотность')\n",
    "\n",
    "random_var_deltas = np.array(random_deltas).var(ddof = 1)\n",
    "stratified_var_deltas = np.array(stratified_deltas_strat_mean).var(ddof = 1)\n",
    "\n",
    "print(f'Дисперсия разницы средних при случаном семплировании: {random_var_deltas}')\n",
    "print(f'Дисперсия разницы средних при стратифицированном семплировании (и стратифицированном среднем): {stratified_var_deltas}')\n",
    "\n",
    "print(f'Произошло снижение дисперсии разницы средних в {round(random_var_deltas / stratified_var_deltas, 2)} раз(а)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29262f34",
   "metadata": {},
   "source": [
    "### Вычисляем ошибку первого (на АА тесте) и второго (на АВ тесте) рода при случайном семплировании и стратифицированном среднем (и соответственно стратифицированной дисперсии) (постстратификация)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d75cb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_type_errors = []\n",
    "second_type_errors = []\n",
    "\n",
    "for _ in tqdm.tqdm(range(10000)):\n",
    "    # Случайное семплирование!\n",
    "    control_aa, pilot_aa = get_random_data(strats, sample_size, strat_to_param)\n",
    "    control_ab, pilot_ab = get_random_data(strats, sample_size, strat_to_param, effect)\n",
    "    \n",
    "    # Стратифицированный подсчет среднего и дисперсии!\n",
    "    pvalue_aa, delta = ttest_strat(control_aa, pilot_aa, weights, return_deltas = True)\n",
    "    first_type_errors.append(pvalue_aa < alpha)\n",
    "    stratified_deltas_strat_mean.append(delta)\n",
    "    \n",
    "    pvalue_ab = ttest_strat(control_ab, pilot_ab, weights, return_deltas = False)\n",
    "    second_type_errors.append(pvalue_ab >= alpha)\n",
    "\n",
    "prop_first_type_errors = np.mean(first_type_errors)\n",
    "prop_second_type_errors = np.mean(second_type_errors)\n",
    "print(f'prop_first_type_errors = {prop_first_type_errors:0.3f}')\n",
    "print(f'prop_second_type_errors = {prop_second_type_errors:0.3f}')\n",
    "print(f'Произошло снижение ошибки II рода в {round(prop_random_second_type_errors / prop_second_type_errors, 2)} раз(а)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2810cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot({'Случайное семплирвоание': random_deltas, 'Cлучайное семплирование \\n (и стратифицированное среднее)': stratified_deltas_strat_mean}, kind='kde')\n",
    "plt.title('Распределение разницы средних при разных видах усреднения')\n",
    "plt.ylabel('Плотность')\n",
    "\n",
    "random_var_deltas = np.array(random_deltas).var(ddof = 1)\n",
    "stratified_var_deltas = np.array(stratified_deltas_strat_mean).var(ddof = 1)\n",
    "\n",
    "print(f'Дисперсия разницы средних при случаном семплировании: {random_var_deltas}')\n",
    "print(f'Дисперсия разницы средних при случаном семплировании (и стратифицированном среднем): {stratified_var_deltas}')\n",
    "\n",
    "print(f'Произошло снижение дисперсии разницы средних в {round(random_var_deltas / stratified_var_deltas, 2)} раз(а)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5bed19",
   "metadata": {},
   "source": [
    "При достаточно большом объёме данных отличия между стратификацией и постстратификацией минимальны"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18a9f09",
   "metadata": {},
   "source": [
    "# Utilizing pre-experiment data (UED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377be116",
   "metadata": {},
   "source": [
    "![](img/corr_theorem.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b590ae2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_correlated_variables(rho, mu_x, std_x, mu_y, std_y, n):\n",
    "    '''\n",
    "    Генерирует две случайные величины с заранее заданной корреляцией.\n",
    "    Предварителньо задаются параментры величин:\n",
    "    mu_x, std_x - математическое ожидание и стандартное отклонение СВ X\n",
    "    mu_y, std_y - математическое ожидание и стандартное отклонение СВ Y\n",
    "    rho - коэффициент корреляции Пирсона между СВ Х и СВ Y\n",
    "    n - число наблюдений\n",
    "    '''\n",
    "    \n",
    "    Z_1 = stats.norm().rvs(n)\n",
    "    Z_2 = stats.norm().rvs(n)\n",
    "    \n",
    "    X = std_x * Z_1 + mu_x\n",
    "\n",
    "    Y = std_y * (rho * Z_1 + (1 - rho ** 2)**0.5 * Z_2) + mu_y\n",
    "\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16ce565",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = generate_correlated_variables(0.8, 4, 2, 4, 2, 1000)\n",
    "scipy.stats.pearsonr(X, Y)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fddf691",
   "metadata": {},
   "source": [
    "## Данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29a8cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1100*2\n",
    "\n",
    "treatment_effect = 100\n",
    "\n",
    "mu_pre = 2500\n",
    "std_pre = 800\n",
    "\n",
    "mu_exp = 2500\n",
    "std_exp = 800\n",
    "\n",
    "corr = 0.7\n",
    "\n",
    "metric_pre, metric_exp = generate_correlated_variables(corr, mu_pre, std_pre, mu_exp, std_exp, n)\n",
    "\n",
    "is_treatment = np.concatenate((np.zeros(n//2, dtype = int), np.ones(n//2, dtype = int)), axis=None)\n",
    "np.random.shuffle(is_treatment)\n",
    "\n",
    "data = pd.DataFrame({'metric_pre': metric_pre,\n",
    "                     'metric_exp': metric_exp,\n",
    "                     'is_treatment': is_treatment})\n",
    "\n",
    "data.loc[data.is_treatment == 1, 'metric_exp'] += treatment_effect\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec13de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Корреляция между метрикой до эксперимента\\nи во время эксперимента: {scipy.stats.pearsonr(data[\"metric_pre\"], data[\"metric_exp\"])[0]}')\n",
    "print()\n",
    "print('Среднее значение метрики:')\n",
    "print(f\"До эксперимента в контрольной группе: {round(data[data.is_treatment == 0]['metric_pre'].mean(), 2)}\")\n",
    "print(f\"До эксперимента в тестовой группе: {round(data[data.is_treatment == 1]['metric_pre'].mean(), 2)}\")\n",
    "print(f\"Во время эксперимента в контрольной группе: {round(data[data.is_treatment == 0]['metric_exp'].mean(), 2)}\")\n",
    "print(f\"Во время эксперимента в тестовой группе: {round(data[data.is_treatment == 1]['metric_exp'].mean(), 2)}\")\n",
    "print(f\"До эксперимента: {round(data['metric_pre'].mean(), 2)}\")\n",
    "print(f\"Во время эксперимента: {round(data['metric_exp'].mean(), 2)}\")\n",
    "print()\n",
    "print('Стандартное отклонение метрики:')\n",
    "print(f\"До эксперимента в контрольной группе: {round(data[data.is_treatment == 0]['metric_pre'].std(ddof = 1), 2)}\")\n",
    "print(f\"До эксперимента в тестовой группе: {round(data[data.is_treatment == 1]['metric_pre'].std(ddof = 1), 2)}\")\n",
    "print(f\"Во время эксперимента в контрольной группе: {round(data[data.is_treatment == 0]['metric_exp'].std(ddof = 1), 2)}\")\n",
    "print(f\"Во время эксперимента в тестовой группе: {round(data[data.is_treatment == 1]['metric_exp'].std(ddof = 1), 2)}\")\n",
    "print(f\"До эксперимента: {round(data['metric_pre'].std(ddof = 1), 2)}\")\n",
    "print(f\"Во время эксперимента: {round(data['metric_exp'].std(ddof = 1), 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b10528",
   "metadata": {},
   "source": [
    "Проведем АВ-тесты в разных вариантах:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c062cc73",
   "metadata": {},
   "source": [
    "## Парная регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cbb690",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smf.ols('metric_exp ~ is_treatment', data = data).fit()\n",
    "model.summary().tables[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd3618d",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, pvalue = stats.ttest_ind(data[data['is_treatment'] == 1].metric_exp, data[data['is_treatment'] == 0].metric_exp)\n",
    "print(f'{pvalue:0.10f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e02b55",
   "metadata": {},
   "source": [
    "## Добавляем в регрессию ковариант"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a96da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smf.ols('metric_exp ~ metric_pre + is_treatment', data = data).fit()\n",
    "model.summary().tables[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e285824",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{model.pvalues.is_treatment:0.10f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3042f3e1",
   "metadata": {},
   "source": [
    "# CUPED"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b959b4c",
   "metadata": {},
   "source": [
    "$$Y_{CUPED} = Y - \\theta X$$\n",
    "\n",
    "$$\\theta = \\frac{cov(X, Y)}{Var(X)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b417a9",
   "metadata": {},
   "source": [
    "## Считаем $\\theta$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95a3b45",
   "metadata": {},
   "source": [
    "Так:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f53bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_X_Y = np.cov(data['metric_pre'], \n",
    "                 data['metric_exp'],\n",
    "                 ddof=1)[0, 1]\n",
    "\n",
    "var_X = np.var(data['metric_pre'], ddof=1)\n",
    "\n",
    "theta = cov_X_Y / var_X\n",
    "\n",
    "theta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc4a9c5",
   "metadata": {},
   "source": [
    "Или так:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1387e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smf.ols('metric_exp ~ metric_pre', data = data).fit()\n",
    "model.summary().tables[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8373e910",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = model.params[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede9e0b4",
   "metadata": {},
   "source": [
    "## I способ подсчета $Y_{CUPED}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab81c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['metric_exp_cuped_1'] = data['metric_exp'] - (theta * (data['metric_pre'] - data['metric_pre'].mean()))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf4f8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_metr_exp =  data['metric_exp'].std(ddof = 1)\n",
    "std_metr_exp_cuped_1 =  data['metric_exp_cuped_1'].std(ddof = 1)\n",
    "\n",
    "print(f'Стандартное отклонение метрики \\nво время эксперимента: {round(std_metr_exp, 2)}')\n",
    "print(f'Стандартное отклонение метрики \\nво время эксперимента \\nпосле cuped-преобразования: {round(std_metr_exp_cuped_1, 2)}')\n",
    "print(f'После преобразования стандартное \\nотклонение метрики во время \\nэксперимента уменьшилась на {round(100 - std_metr_exp_cuped_1 * 100 / std_metr_exp, 2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4204ab2",
   "metadata": {},
   "source": [
    "Проверка формул: \n",
    "* падение дисперсии среднего значения метрики в $[1 - {\\rho}^2(X, Y)]$ раз \n",
    "* неизменность математического ожидания метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eea6b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_Y = np.std(data['metric_exp'])**2\n",
    "var_Y_mean = var_Y / len(data['metric_exp'])\n",
    "\n",
    "var_Y_cuped_1 = np.std(data['metric_exp_cuped_1'])**2\n",
    "var_Y_cuped_1_mean = var_Y_cuped_1 / len(data['metric_exp_cuped_1'])\n",
    "\n",
    "corr_X_Y = np.corrcoef([data['metric_pre'], \n",
    "                        data['metric_exp']])[0,1]\n",
    "\n",
    "print(f'Дисперсия среднего\\n исходной метрики = {var_Y_mean:0.2f}')\n",
    "print(f'Дисперсия среднего\\n cuped-преобразованной метрики = {var_Y_cuped_1_mean:0.2f}')\n",
    "print(f'(1 - rho^2) = {1 - corr_X_Y**2:0.3f}')\n",
    "print(f'Отношение дисперсий = {var_Y_cuped_1_mean / var_Y_mean:0.3f}')\n",
    "\n",
    "print()\n",
    "\n",
    "print(f'Cреднее значение метрики\\n до преобразования: {round(data[\"metric_exp\"].mean(), 2)}')\n",
    "print(f'Cреднее значение метрики\\n после преобразования: {round(data[\"metric_exp_cuped_1\"].mean(), 2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265d56f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smf.ols('metric_exp_cuped_1 ~ is_treatment', data = data).fit()\n",
    "model.summary().tables[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6530ff95",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, pvalue = stats.ttest_ind(data[data['is_treatment'] == 1].metric_exp_cuped_1, \n",
    "                            data[data['is_treatment'] == 0].metric_exp_cuped_1)\n",
    "print(f'{pvalue:0.10f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54031a60",
   "metadata": {},
   "source": [
    "## II способ подсчета $Y_{CUPED}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f466bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smf.ols('metric_exp ~ metric_pre', data = data).fit()\n",
    "\n",
    "data['metric_exp_cuped_2'] = model.resid + data['metric_exp'].mean()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c4b808",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_metr_exp =  data['metric_exp'].std(ddof = 1)\n",
    "std_metr_exp_cuped_2 =  data['metric_exp_cuped_2'].std(ddof = 1)\n",
    "\n",
    "print(f'Стандартное отклонение метрики во время эксперимента: {round(std_metr_exp, 2)}')\n",
    "print(f'Стандартное отклонение метрики во время эксперимента после cuped-преобразования: {round(std_metr_exp_cuped_2, 2)}')\n",
    "print(f'После преобразования стандартное отклонение метрики во время эксперимента уменьшилась на {round(100 - std_metr_exp_cuped_2 * 100 / std_metr_exp, 2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32c73ac",
   "metadata": {},
   "source": [
    "Проверка формул: \n",
    "* падение дисперсии среднего значения метрики в $[1 - {\\rho}^2(X, Y)]$ раз \n",
    "* неизменность математического ожидания метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ac9b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_Y = np.std(data['metric_exp'])**2\n",
    "var_Y_mean = var_Y / len(data['metric_exp'])\n",
    "\n",
    "var_Y_cuped_2 = np.std(data['metric_exp_cuped_2'])**2\n",
    "var_Y_cuped_2_mean = var_Y_cuped_2 / len(data['metric_exp_cuped_2'])\n",
    "\n",
    "corr_X_Y = np.corrcoef([data['metric_pre'], \n",
    "                        data['metric_exp']])[0,1]\n",
    "\n",
    "print(f'Var(Y_mean) = {var_Y_mean:0.2f}')\n",
    "print(f'Var(Y_cuped_2_mean) = {var_Y_cuped_2_mean:0.2f}')\n",
    "print(f'(1 - rho^2) = {1 - corr_X_Y**2:0.3f}')\n",
    "print(f'Var(Y_cuped_2_mean) / Var(Y_mean) = {var_Y_cuped_2_mean / var_Y_mean:0.3f}')\n",
    "\n",
    "print()\n",
    "\n",
    "print(f'Cреднее значение метрики до преобразования: {data[\"metric_exp\"].mean()}')\n",
    "print(f'Cреднее значение метрики после преобразования: {data[\"metric_exp_cuped_2\"].mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b8161d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smf.ols('metric_exp_cuped_2 ~ is_treatment', data = data).fit()\n",
    "model.summary().tables[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b14f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, pvalue = stats.ttest_ind(data[data['is_treatment'] == 1].metric_exp_cuped_2,  \n",
    "                            data[data['is_treatment'] == 0].metric_exp_cuped_2)\n",
    "print(f'{pvalue:0.10f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5514a9",
   "metadata": {},
   "source": [
    "## Визуализация"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b8884a",
   "metadata": {},
   "source": [
    "Наглядное сокращение диспресии преобразованной метрики (хвосты распределения становятся менее \"тяжелыми\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bd2baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "ax_1 = axs[0]\n",
    "ax_2 = axs[1]\n",
    "\n",
    "sns.kdeplot(x = data[data.is_treatment == 0]['metric_exp'], \n",
    "            data = data, label = 'Initial', fill = True, alpha = 0.1, color = 'red', ax = ax_1)\n",
    "sns.kdeplot(x = data[data.is_treatment == 0]['metric_exp_cuped_3'], \n",
    "            data = data, label = 'CUPED transformed', fill = True, alpha = 0.1, color = 'blue', ax = ax_1)\n",
    "ax_1.set_title('Without treatment')\n",
    "ax_1.legend()\n",
    "\n",
    "sns.kdeplot(x = data[data.is_treatment == 1]['metric_exp'],\n",
    "            data = data, label = 'Initial', fill = True, alpha = 0.1, color = 'red', ax = ax_2)\n",
    "sns.kdeplot(x = data[data.is_treatment == 1]['metric_exp_cuped_3'], \n",
    "            data = data, label = 'CUPED transformed', fill = True, alpha = 0.1, color = 'blue', ax = ax_2)\n",
    "ax_2.set_title('With treatment')\n",
    "ax_2.legend()\n",
    "\n",
    "fig, axs = plt.subplots(1, 1, figsize=(16, 6))\n",
    "sns.kdeplot(x = 'metric_exp', \n",
    "            data = data, label = 'Initial', fill = True, alpha = 0.1, color = 'red', ax = axs)\n",
    "sns.kdeplot(x = 'metric_exp_cuped_3', \n",
    "            data = data, label = 'CUPED transformed', fill = True, alpha = 0.1, color = 'blue', ax = axs)\n",
    "axs.set_title('All users')\n",
    "axs.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7223df",
   "metadata": {},
   "source": [
    "## Ошибки I и II рода"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2018997",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1100*2\n",
    "\n",
    "alpha = 0.05\n",
    "\n",
    "treatment_effect = 100\n",
    "\n",
    "mu_pre = 2500\n",
    "std_pre = 800\n",
    "\n",
    "mu_exp = 2500\n",
    "std_exp = 800\n",
    "\n",
    "corr = 0.8\n",
    "\n",
    "simple_first_type_errors = []\n",
    "simple_second_type_errors = []\n",
    "\n",
    "cuped_first_type_errors = []\n",
    "cuped_second_type_errors = []\n",
    "\n",
    "simple_deltas = []\n",
    "cuped_deltas = []\n",
    "\n",
    "for _ in tqdm.tqdm(list(range(10000))):\n",
    "    \n",
    "    metric_pre, metric_exp = generate_correlated_variables(corr, mu_pre, std_pre, mu_exp, std_exp, n)\n",
    "\n",
    "    is_treatment = np.concatenate((np.zeros(n//2, dtype = int), np.ones(n//2, dtype = int)), axis=None)\n",
    "    np.random.shuffle(is_treatment)\n",
    "\n",
    "    data_no_treatment = pd.DataFrame({'metric_pre': metric_pre,\n",
    "                         'metric_exp': metric_exp,\n",
    "                         'is_treatment': is_treatment})\n",
    "    \n",
    "    # simple for AA\n",
    "    \n",
    "    control_one = data_no_treatment[data_no_treatment.is_treatment == 0]\n",
    "    control_two = data_no_treatment[data_no_treatment.is_treatment == 1]\n",
    "        \n",
    "    _, pvalue_aa = stats.ttest_ind(control_one['metric_exp'], control_two['metric_exp'])\n",
    "    simple_first_type_errors.append(pvalue_aa < alpha)\n",
    "    \n",
    "    # simple for AB\n",
    "    \n",
    "    data_with_treatment = copy.deepcopy(data_no_treatment)\n",
    "    data_with_treatment.loc[data_with_treatment.is_treatment == 1, 'metric_exp'] += treatment_effect\n",
    "    \n",
    "    control = data_with_treatment[data_with_treatment.is_treatment == 0]\n",
    "    pilot = data_with_treatment[data_with_treatment.is_treatment == 1]\n",
    "    \n",
    "    _, pvalue_ab = stats.ttest_ind(control['metric_exp'], pilot['metric_exp'])\n",
    "    simple_second_type_errors.append(pvalue_ab >= alpha)\n",
    "    \n",
    "    simple_deltas.append(pilot['metric_exp'].mean() - control['metric_exp'].mean())\n",
    "    \n",
    "    # CUPED for AA\n",
    "    \n",
    "    cov_X_Y = np.cov(data_no_treatment['metric_pre'], \n",
    "                     data_no_treatment['metric_exp'],\n",
    "                     ddof=1)[0, 1]\n",
    "\n",
    "    var_X = np.var(data_no_treatment['metric_pre'], ddof=1)\n",
    "\n",
    "    theta = cov_X_Y / var_X\n",
    "    \n",
    "    data_no_treatment['metric_exp_cuped'] = data_no_treatment['metric_exp'] - \\\n",
    "                                        (theta * (data_no_treatment['metric_pre'] - data_no_treatment['metric_pre'].mean()))\n",
    "    \n",
    "    control_one = data_no_treatment[data_no_treatment.is_treatment == 0]\n",
    "\n",
    "    control_two = data_no_treatment[data_no_treatment.is_treatment == 1]\n",
    "    \n",
    "    _, pvalue_aa = stats.ttest_ind(control_one['metric_exp_cuped'], control_two['metric_exp_cuped'])\n",
    "    cuped_first_type_errors.append(pvalue_aa < alpha)\n",
    "    \n",
    "    # CUPED for AB\n",
    "    \n",
    "    cov_X_Y = np.cov(data_with_treatment['metric_pre'], \n",
    "                     data_with_treatment['metric_exp'],\n",
    "                     ddof=1)[0, 1]\n",
    "\n",
    "    var_X = np.var(data_with_treatment['metric_pre'], ddof=1)\n",
    "\n",
    "    theta = cov_X_Y / var_X\n",
    "    \n",
    "    data_with_treatment['metric_exp_cuped'] = data_with_treatment['metric_exp'] - \\\n",
    "                                        (theta * (data_with_treatment['metric_pre'] - data_with_treatment['metric_pre'].mean()))\n",
    "    \n",
    "    control = data_with_treatment[data_with_treatment.is_treatment == 0]\n",
    "\n",
    "    pilot = data_with_treatment[data_with_treatment.is_treatment == 1]\n",
    "      \n",
    "    _, pvalue_ab = stats.ttest_ind(control['metric_exp_cuped'], pilot['metric_exp_cuped'])\n",
    "    cuped_second_type_errors.append(pvalue_ab >= alpha)\n",
    "    \n",
    "    cuped_deltas.append(pilot['metric_exp_cuped'].mean() - control['metric_exp_cuped'].mean())\n",
    "\n",
    "prop_simple_first_type_errors = np.mean(simple_first_type_errors)\n",
    "prop_simple_second_type_errors = np.mean(simple_second_type_errors)\n",
    "print(f'prop_simple_first_type_errors = {prop_simple_first_type_errors:0.3f}')\n",
    "print(f'prop_simple_second_type_errors = {prop_simple_second_type_errors:0.3f}')\n",
    "\n",
    "prop_cuped_first_type_errors = np.mean(cuped_first_type_errors)\n",
    "prop_cuped_second_type_errors = np.mean(cuped_second_type_errors)\n",
    "print(f'prop_cuped_first_type_errors = {prop_cuped_first_type_errors:0.3f}')\n",
    "print(f'prop_cuped_second_type_errors = {prop_cuped_second_type_errors:0.3f}')\n",
    "\n",
    "print(f'Произошло снижение ошибки II рода в {round(prop_simple_second_type_errors / prop_cuped_second_type_errors, 2)} раз(а)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b3cd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot({'Simple': simple_deltas, 'CUPED': cuped_deltas}, kind='kde')\n",
    "plt.title('Распределение разницы средних')\n",
    "plt.ylabel('Плотность')\n",
    "\n",
    "simple_var_deltas = np.array(simple_deltas).var(ddof = 1)\n",
    "cuped_var_deltas = np.array(cuped_deltas).var(ddof = 1)\n",
    "\n",
    "print(f'Дисперсия разницы средних при обычном АВ-тесте: {simple_var_deltas}')\n",
    "print(f'Дисперсия разницы средних при АВ-тесте с использованием CUPED-преобразования: {cuped_var_deltas}')\n",
    "\n",
    "print(f'Произошло снижение дисперсии разницы средних в {round(simple_var_deltas / cuped_var_deltas, 2)} раз(а)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0e589e",
   "metadata": {},
   "source": [
    "**CUPED снизил дисперсию разницы средних (и соответственно ошибку II рода) больше, чем стратификация**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f26c38",
   "metadata": {},
   "source": [
    "# CUMPED"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4faffdd6",
   "metadata": {},
   "source": [
    "Добавляем в модель не одну, а несколько ковариант:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffcf702",
   "metadata": {},
   "source": [
    "## Данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18922d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_several_correlated_variables(mu_x, std_x, params, n):\n",
    "    '''\n",
    "    Генерирует несколько случайных величин с заранее заданной корреляцией.\n",
    "    Предварителньо задаются параментры величин:\n",
    "    mu_x, std_x - математическое ожидание и стандартное отклонение СВ X\n",
    "    params - cписок кортежей (mu, std, rho) с математическими ожиданиями и стандартными\n",
    "    отклонениями других СВ, заданной корреляцией Пирсона между СВ Х и другими СВ\n",
    "    n - число наблюдений\n",
    "    '''\n",
    "    \n",
    "    Z_1 = stats.norm().rvs(n)\n",
    "    Z_2 = stats.norm().rvs(n)\n",
    "    \n",
    "    X = std_x * Z_1 + mu_x\n",
    "    \n",
    "    result = pd.DataFrame({'metric': X})\n",
    "    \n",
    "    for n, (mu_other, std_other, rho) in enumerate(params):\n",
    "        other = std_other * (rho * Z_1 + (1 - rho ** 2)**0.5 * Z_2) + mu_other\n",
    "        result[f'X{n}'] = other\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cafe15",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2*1100\n",
    "\n",
    "treatment_effect = 50\n",
    "\n",
    "mu_metr = 2500\n",
    "std_metr = 800\n",
    "params = [(2500, 800, 0.75), (2250, 500, 0.75), (2800, 900, 0.75)]\n",
    "\n",
    "data = generate_several_correlated_variables(mu_metr, std_metr, params, n)\n",
    "\n",
    "is_treatment = np.concatenate((np.zeros(n//2, dtype = int), np.ones(n//2, dtype = int)), axis=None)\n",
    "np.random.shuffle(is_treatment)\n",
    "data['is_treatment'] = is_treatment\n",
    "data.loc[data.is_treatment == 1, 'metric'] += treatment_effect\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e329615",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Среднее значение метрики:')\n",
    "print(f\"В контрольной группе: {round(data[data.is_treatment == 0]['metric'].mean(), 2)}\")\n",
    "print(f\"В тестовой группе: {round(data[data.is_treatment == 1]['metric'].mean(), 2)}\")\n",
    "print()\n",
    "print('Стандартное отклонение метрики:')\n",
    "print(f\"В контрольной группе: {round(data[data.is_treatment == 0]['metric'].std(ddof = 1), 2)}\")\n",
    "print(f\"В тестовой группе: {round(data[data.is_treatment == 1]['metric'].std(ddof = 1), 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7534577",
   "metadata": {},
   "source": [
    "## Парная регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28ad9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smf.ols('metric ~ is_treatment', data = data).fit()\n",
    "model.summary().tables[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44789b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{model.pvalues.is_treatment:0.15f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d1c1bd",
   "metadata": {},
   "source": [
    "## Множественная регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de7f066",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smf.ols('metric ~ X0 + X1 + X2 + is_treatment', data = data).fit()\n",
    "model.summary().tables[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1b28ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{model.pvalues.is_treatment:0.15f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00298459",
   "metadata": {},
   "source": [
    "## CUMPED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ad7afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smf.ols('metric ~ X0 + X1 + X2 + is_treatment', data = data).fit()\n",
    "model.summary().tables[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e27864e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['metric_cumped'] = data['metric'] - (model.params[0] + \\\n",
    "                                            model.params[1] * data['X0'] + \\\n",
    "                                            model.params[2] * data['X1'] + \\\n",
    "                                            model.params[3] * data['X2']) + data['metric'].mean()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a60cb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, pvalue = stats.ttest_ind(data[data['is_treatment'] == 1].metric_cumped, \n",
    "                            data[data['is_treatment'] == 0].metric_cumped)\n",
    "print(f'{pvalue:0.10f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144ec2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Дисперсия исходной метрики: {data['metric'].var(ddof = 1)}\")\n",
    "print(f\"Дисперсия метрики после cumped-преобразования: {data['metric_cumped'].var(ddof = 1)}\")\n",
    "print(f\"Дисперсия метрики снизилась в {round(data['metric'].var(ddof = 1) / data['metric_cumped'].var(ddof = 1), 2)} раз(а)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20ae429",
   "metadata": {},
   "source": [
    "## Визуализация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a47fa41",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "ax_1 = axs[0]\n",
    "ax_2 = axs[1]\n",
    "\n",
    "sns.kdeplot(x = data[data.is_treatment == 0]['metric'], \n",
    "            data = data, label = 'Initial', fill = True, alpha = 0.1, color = 'red', ax = ax_1)\n",
    "sns.kdeplot(x = data[data.is_treatment == 0]['metric_cumped'], \n",
    "            data = data, label = 'CUMPED transformed', fill = True, alpha = 0.1, color = 'blue', ax = ax_1)\n",
    "ax_1.set_title('Without treatment')\n",
    "ax_1.legend()\n",
    "\n",
    "sns.kdeplot(x = data[data.is_treatment == 1]['metric'],\n",
    "            data = data, label = 'Initial', fill = True, alpha = 0.1, color = 'red', ax = ax_2)\n",
    "sns.kdeplot(x = data[data.is_treatment == 1]['metric_cumped'], \n",
    "            data = data, label = 'CUMPED transformed', fill = True, alpha = 0.1, color = 'blue', ax = ax_2)\n",
    "ax_2.set_title('With treatment')\n",
    "ax_2.legend()\n",
    "\n",
    "fig, axs = plt.subplots(1, 1, figsize=(16, 6))\n",
    "sns.kdeplot(x = 'metric', \n",
    "            data = data, label = 'Initial', fill = True, alpha = 0.1, color = 'red', ax = axs)\n",
    "sns.kdeplot(x = 'metric_cumped', \n",
    "            data = data, label = 'CUMPED transformed', fill = True, alpha = 0.1, color = 'blue', ax = axs)\n",
    "axs.set_title('All users')\n",
    "axs.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac5dd37",
   "metadata": {},
   "source": [
    "## Ошибки I и II рода"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7d36f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1100*2\n",
    "\n",
    "alpha = 0.05\n",
    "\n",
    "treatment_effect = 100\n",
    "\n",
    "mu_metr = 2500\n",
    "std_metr = 800\n",
    "params = [(2500, 800, 0.8), (2250, 500, 0.8), (2800, 900, 0.8)]\n",
    "\n",
    "simple_first_type_errors = []\n",
    "simple_second_type_errors = []\n",
    "\n",
    "cumped_first_type_errors = []\n",
    "cumped_second_type_errors = []\n",
    "\n",
    "simple_deltas = []\n",
    "cumped_deltas = []\n",
    "\n",
    "for _ in tqdm.tqdm(list(range(10000))):\n",
    "    \n",
    "    data = generate_several_correlated_variables(mu_metr, std_metr, params, n)\n",
    "\n",
    "    is_treatment = np.concatenate((np.zeros(n//2, dtype = int), np.ones(n//2, dtype = int)), axis=None)\n",
    "    np.random.shuffle(is_treatment)\n",
    "    data['is_treatment'] = is_treatment\n",
    "\n",
    "    data_no_treatment = copy.deepcopy(data)\n",
    "    \n",
    "    # simple for AA\n",
    "    \n",
    "    control_one = data_no_treatment[data_no_treatment.is_treatment == 0]\n",
    "    control_two = data_no_treatment[data_no_treatment.is_treatment == 1]\n",
    "        \n",
    "    _, pvalue_aa = stats.ttest_ind(control_one['metric'], control_two['metric'])\n",
    "    simple_first_type_errors.append(pvalue_aa < alpha)\n",
    "    \n",
    "    # simple for AB\n",
    "    \n",
    "    data_with_treatment = copy.deepcopy(data)\n",
    "    data_with_treatment.loc[data_with_treatment.is_treatment == 1, 'metric'] += treatment_effect\n",
    "    \n",
    "    control = data_with_treatment[data_with_treatment.is_treatment == 0]\n",
    "    pilot = data_with_treatment[data_with_treatment.is_treatment == 1]\n",
    "    \n",
    "    _, pvalue_ab = stats.ttest_ind(control['metric'], pilot['metric'])\n",
    "    simple_second_type_errors.append(pvalue_ab >= alpha)\n",
    "    \n",
    "    simple_deltas.append(pilot['metric'].mean() - control['metric'].mean())\n",
    "    \n",
    "    # CUMPED for AA\n",
    "    \n",
    "    model = smf.ols('metric ~ X0 + X1 + X2 + is_treatment', data = data_no_treatment).fit()\n",
    "    data_no_treatment['metric_cumped'] = data_no_treatment['metric'] - (model.params[0] + \\\n",
    "                                              model.params[1] * (data_no_treatment['X0'] - data_no_treatment['X0'].mean()) + \\\n",
    "                                              model.params[2] * (data_no_treatment['X1'] - data_no_treatment['X1'].mean()) + \\\n",
    "                                              model.params[3] * (data_no_treatment['X2'] - data_no_treatment['X2'].mean()))\n",
    "    \n",
    "    control_one = data_no_treatment[data_no_treatment.is_treatment == 0]\n",
    "\n",
    "    control_two = data_no_treatment[data_no_treatment.is_treatment == 1]\n",
    "    \n",
    "    _, pvalue_aa = stats.ttest_ind(control_one['metric_cumped'], control_two['metric_cumped'])\n",
    "    cumped_first_type_errors.append(pvalue_aa < alpha)\n",
    "    \n",
    "    # CUMPED for AB\n",
    "    \n",
    "    model = smf.ols('metric ~ X0 + X1 + X2 + is_treatment', data = data_with_treatment).fit()\n",
    "    data_with_treatment['metric_cumped'] = data_with_treatment['metric'] - (model.params[0] + \\\n",
    "                                              model.params[1] * (data_with_treatment['X0'] - data_with_treatment['X0'].mean()) + \\\n",
    "                                              model.params[2] * (data_with_treatment['X1'] - data_with_treatment['X1'].mean()) + \\\n",
    "                                              model.params[3] * (data_with_treatment['X2'] - data_with_treatment['X2'].mean()))\n",
    "    \n",
    "    control = data_with_treatment[data_with_treatment.is_treatment == 0]\n",
    "\n",
    "    pilot = data_with_treatment[data_with_treatment.is_treatment == 1]\n",
    "    \n",
    "    _, pvalue_ab = stats.ttest_ind(control['metric_cumped'], pilot['metric_cumped'])\n",
    "    cumped_second_type_errors.append(pvalue_ab >= alpha)\n",
    "    \n",
    "    cumped_deltas.append(pilot['metric_cumped'].mean() - control['metric_cumped'].mean())\n",
    "\n",
    "prop_simple_first_type_errors = np.mean(simple_first_type_errors)\n",
    "prop_simple_second_type_errors = np.mean(simple_second_type_errors)\n",
    "print(f'prop_simple_first_type_errors = {prop_simple_first_type_errors:0.3f}')\n",
    "print(f'prop_simple_second_type_errors = {prop_simple_second_type_errors:0.3f}')\n",
    "\n",
    "prop_cumped_first_type_errors = np.mean(cumped_first_type_errors)\n",
    "prop_cumped_second_type_errors = np.mean(cumped_second_type_errors)\n",
    "print(f'prop_cumped_first_type_errors = {prop_cumped_first_type_errors:0.3f}')\n",
    "print(f'prop_cumped_second_type_errors = {prop_cumped_second_type_errors:0.3f}')\n",
    "\n",
    "print(f'Произошло снижение ошибки II рода в {round(prop_simple_second_type_errors / prop_cumped_second_type_errors, 2)} раз(а)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e70935",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot({'Simple': simple_deltas, 'CUMPED': cumped_deltas}, kind='kde')\n",
    "plt.title('Распределение разницы средних')\n",
    "plt.ylabel('Плотность')\n",
    "\n",
    "simple_var_deltas = np.array(simple_deltas).var(ddof = 1)\n",
    "cumped_var_deltas = np.array(cumped_deltas).var(ddof = 1)\n",
    "\n",
    "print(f'Дисперсия разницы средних при обычном АВ-тесте: {simple_var_deltas}')\n",
    "print(f'Дисперсия разницы средних при АВ-тесте с использованием CUMPED-преобразования: {cumped_var_deltas}')\n",
    "\n",
    "print(f'Произошло снижение дисперсии разницы средних в {round(simple_var_deltas / cumped_var_deltas, 2)} раз(а)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4109b04",
   "metadata": {},
   "source": [
    "# CUPAC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954e1550",
   "metadata": {},
   "source": [
    "## Данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcfef4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2*1100\n",
    "\n",
    "treatment_effect = 100\n",
    "\n",
    "mu_metr = 2500\n",
    "std_metr = 800\n",
    "params = [(2500, 800, 0.75), (2250, 500, 0.75), (2800, 900, 0.75)]\n",
    "\n",
    "data_train = generate_several_correlated_variables(mu_metr, std_metr, params, n)\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93eaf1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2*1100\n",
    "\n",
    "treatment_effect = 100\n",
    "\n",
    "mu_metr = 2500\n",
    "std_metr = 800\n",
    "params = [(2500, 800, 0.75), (2250, 500, 0.75), (2800, 900, 0.75)]\n",
    "\n",
    "data_test = generate_several_correlated_variables(mu_metr, std_metr, params, n)\n",
    "\n",
    "is_treatment = np.concatenate((np.zeros(n//2, dtype = int), np.ones(n//2, dtype = int)), axis=None)\n",
    "np.random.shuffle(is_treatment)\n",
    "data_test['is_treatment'] = is_treatment\n",
    "data_test.loc[data_test.is_treatment == 1, 'metric'] += treatment_effect\n",
    "\n",
    "data_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47282776",
   "metadata": {},
   "source": [
    "## Парная регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10131ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smf.ols('metric ~ is_treatment', data = data_test).fit()\n",
    "model.summary().tables[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c763ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{model.pvalues.is_treatment:0.15f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a62a31",
   "metadata": {},
   "source": [
    "## Множественная регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffc927f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smf.ols('metric ~ X0 + X1 + X2 + is_treatment', data = data_test).fit()\n",
    "model.summary().tables[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd1575c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{model.pvalues.is_treatment:0.15f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200ce6f0",
   "metadata": {},
   "source": [
    "## CUPAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162ac7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(n_estimators = 50, \n",
    "                              criterion = 'squared_error', \n",
    "                              max_depth = 7)\n",
    "model.fit(X = data_train[['X0', 'X1', 'X2']], y = data_train['metric'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab600c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test['metric_cupac'] = data_test['metric'] - model.predict(data_test[['X0', 'X1', 'X2']]) + data_test['metric'].mean()\n",
    "data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a88181b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, pvalue = stats.ttest_ind(data_test[data_test['is_treatment'] == 1].metric_cupac, \n",
    "                            data_test[data_test['is_treatment'] == 0].metric_cupac)\n",
    "print(f'{pvalue:0.10f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0fd82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Дисперсия исходной метрики: {data_test['metric'].var(ddof = 1)}\")\n",
    "print(f\"Дисперсия cupac-преобразованной метрики: {data_test['metric_cupac'].var(ddof = 1)}\")\n",
    "print(f\"После преобразования стандартное отклонение метрики уменьшилась на {round(100 - data_test['metric_cupac'].var(ddof = 1) * 100 / data_test['metric'].var(ddof = 1), 2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8acac34b",
   "metadata": {},
   "source": [
    "## Визуализация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3159510b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "ax_1 = axs[0]\n",
    "ax_2 = axs[1]\n",
    "\n",
    "sns.kdeplot(x = 'metric', \n",
    "            data = data_test[data_test.is_treatment == 0], label = 'Initial', fill = True, alpha = 0.1, color = 'red', ax = ax_1)\n",
    "sns.kdeplot(x = 'metric_cupac', \n",
    "            data = data_test[data_test.is_treatment == 0], label = 'CUPAC transformed', fill = True, alpha = 0.1, color = 'blue', ax = ax_1)\n",
    "ax_1.set_title('Without treatment')\n",
    "ax_1.legend()\n",
    "\n",
    "sns.kdeplot(x = 'metric',\n",
    "            data = data_test[data_test.is_treatment == 1], label = 'Initial', fill = True, alpha = 0.1, color = 'red', ax = ax_2)\n",
    "sns.kdeplot(x = 'metric_cupac', \n",
    "            data = data_test[data_test.is_treatment == 1], label = 'CUPAC transformed', fill = True, alpha = 0.1, color = 'blue', ax = ax_2)\n",
    "ax_2.set_title('With treatment')\n",
    "ax_2.legend()\n",
    "\n",
    "fig, axs = plt.subplots(1, 1, figsize=(16, 6))\n",
    "sns.kdeplot(x = 'metric', \n",
    "            data = data_test, label = 'Initial', fill = True, alpha = 0.1, color = 'red', ax = axs)\n",
    "sns.kdeplot(x = 'metric_cupac', \n",
    "            data = data_test, label = 'CUPAC transformed', fill = True, alpha = 0.1, color = 'blue', ax = axs)\n",
    "axs.set_title('All users')\n",
    "axs.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d001b16",
   "metadata": {},
   "source": [
    "## Ошибки I и II рода"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507ca51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1100*2\n",
    "\n",
    "alpha = 0.05\n",
    "\n",
    "treatment_effect = 100\n",
    "\n",
    "mu_metr = 2500\n",
    "std_metr = 800\n",
    "params = [(2500, 800, 0.8), (2250, 500, 0.8), (2800, 900, 0.8)]\n",
    "\n",
    "simple_first_type_errors = []\n",
    "simple_second_type_errors = []\n",
    "\n",
    "cupac_first_type_errors = []\n",
    "cupac_second_type_errors = []\n",
    "\n",
    "simple_deltas = []\n",
    "cupac_deltas = []\n",
    "\n",
    "for _ in tqdm.tqdm(list(range(10000))):\n",
    "    \n",
    "    data_train = generate_several_correlated_variables(mu_metr, std_metr, params, n)\n",
    "    \n",
    "    model = RandomForestRegressor(n_estimators = 50, \n",
    "                              criterion = 'squared_error', \n",
    "                              max_depth = 7).fit(X = data_train[['X0', 'X1', 'X2']], y = data_train['metric'])\n",
    " \n",
    "    data_test = generate_several_correlated_variables(mu_metr, std_metr, params, n)\n",
    "\n",
    "    is_treatment = np.concatenate((np.zeros(n//2, dtype = int), np.ones(n//2, dtype = int)), axis=None)\n",
    "    np.random.shuffle(is_treatment)\n",
    "    data_test['is_treatment'] = is_treatment\n",
    "    \n",
    "    data_no_treatment = copy.deepcopy(data_test)\n",
    "    \n",
    "    # simple for AA\n",
    "    \n",
    "    control_one = data_no_treatment[data_no_treatment.is_treatment == 0]\n",
    "    control_two = data_no_treatment[data_no_treatment.is_treatment == 1]\n",
    "        \n",
    "    _, pvalue_aa = stats.ttest_ind(control_one['metric'], control_two['metric'])\n",
    "    simple_first_type_errors.append(pvalue_aa < alpha)\n",
    "    \n",
    "    # simple for AB\n",
    "    \n",
    "    data_with_treatment = copy.deepcopy(data_test)\n",
    "    data_with_treatment.loc[data_with_treatment.is_treatment == 1, 'metric'] += treatment_effect\n",
    "    \n",
    "    control = data_with_treatment[data_with_treatment.is_treatment == 0]\n",
    "    pilot = data_with_treatment[data_with_treatment.is_treatment == 1]\n",
    "    \n",
    "    _, pvalue_ab = stats.ttest_ind(control['metric'], pilot['metric'])\n",
    "    simple_second_type_errors.append(pvalue_ab >= alpha)\n",
    "    \n",
    "    simple_deltas.append(pilot['metric'].mean() - control['metric'].mean())\n",
    "    \n",
    "    # CUMPED for AA\n",
    "    \n",
    "    data_no_treatment['metric_cupac'] = data_no_treatment['metric'] - \\\n",
    "                                        model.predict(data_no_treatment[['X0', 'X1', 'X2']]) + \\\n",
    "                                        data_no_treatment['metric'].mean()\n",
    "    \n",
    "    control_one = data_no_treatment[data_no_treatment.is_treatment == 0]\n",
    "\n",
    "    control_two = data_no_treatment[data_no_treatment.is_treatment == 1]\n",
    "    \n",
    "    _, pvalue_aa = stats.ttest_ind(control_one['metric_cupac'], control_two['metric_cupac'])\n",
    "    cupac_first_type_errors.append(pvalue_aa < alpha)\n",
    "    \n",
    "    # CUMPED for AB\n",
    "    \n",
    "    data_with_treatment['metric_cupac'] = data_with_treatment['metric'] - \\\n",
    "                                          model.predict(data_with_treatment[['X0', 'X1', 'X2']]) + \\\n",
    "                                          data_with_treatment['metric'].mean()\n",
    "    \n",
    "    control = data_with_treatment[data_with_treatment.is_treatment == 0]\n",
    "\n",
    "    pilot = data_with_treatment[data_with_treatment.is_treatment == 1]\n",
    "    \n",
    "    _, pvalue_ab = stats.ttest_ind(control['metric_cupac'], pilot['metric_cupac'])\n",
    "    cupac_second_type_errors.append(pvalue_ab >= alpha)\n",
    "    \n",
    "    cupac_deltas.append(pilot['metric_cupac'].mean() - control['metric_cupac'].mean())\n",
    "\n",
    "prop_simple_first_type_errors = np.mean(simple_first_type_errors)\n",
    "prop_simple_second_type_errors = np.mean(simple_second_type_errors)\n",
    "print(f'prop_simple_first_type_errors = {prop_simple_first_type_errors:0.3f}')\n",
    "print(f'prop_simple_second_type_errors = {prop_simple_second_type_errors:0.3f}')\n",
    "\n",
    "prop_cupac_first_type_errors = np.mean(cupac_first_type_errors)\n",
    "prop_cupac_second_type_errors = np.mean(cupac_second_type_errors)\n",
    "print(f'prop_cupac_first_type_errors = {prop_cupac_first_type_errors:0.3f}')\n",
    "print(f'prop_cupac_second_type_errors = {prop_cupac_second_type_errors:0.3f}')\n",
    "\n",
    "print(f'Произошло снижение ошибки II рода в {round(prop_simple_second_type_errors / prop_cupac_second_type_errors, 2)} раз(а)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06ccb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot({'Simple': simple_deltas, 'CUPAC': cupac_deltas}, kind='kde')\n",
    "plt.title('Распределение разницы средних')\n",
    "plt.ylabel('Плотность')\n",
    "\n",
    "simple_var_deltas = np.array(simple_deltas).var(ddof = 1)\n",
    "cupac_var_deltas = np.array(cupac_deltas).var(ddof = 1)\n",
    "\n",
    "print(f'Дисперсия разницы средних при обычном АВ-тесте: {simple_var_deltas}')\n",
    "print(f'Дисперсия разницы средних при АВ-тесте с использованием CUPAC-преобразования: {cupac_var_deltas}')\n",
    "\n",
    "print(f'Произошло снижение дисперсии разницы средних в {round(simple_var_deltas / cupac_var_deltas, 2)} раз(а)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81dba9a",
   "metadata": {},
   "source": [
    "Материалы по теме исследования:\n",
    "\n",
    "* https://youtu.be/KvIJ8FCJzr4\n",
    "* https://youtu.be/4_J5pvdG35U\n",
    "* https://youtu.be/saeAPdTTfTM\n",
    "* https://youtu.be/Qrz04qUMgVc\n",
    "* https://youtu.be/rhpzdPRIxBk\n",
    "* https://github.com/bdemeshev/cuped_statistician_viewpoint/blob/main/cuped_stat_viewpoint.pdf\n",
    "* http://quantile.ru/06/06-JW.pdf\n",
    "* http://habr.com/ru/companies/X5Tech/articles/768008"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "298.477px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
